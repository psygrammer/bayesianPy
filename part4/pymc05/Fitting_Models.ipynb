{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Fitting Models \n",
    "\n",
    " #### 지지지난 시간, pyMC 를 실행하기에 필요한 모델을 만드는 데 필요한 데이터들을 어떻게 구현하는지 알아보았습니다. \n",
    " #### (Stochastic, Deterministic, Potential)\n",
    "\n",
    " #### 이번 장에서는, 만들어진 데이터 셋으로 계산 모델을 만들고, pyMC 에서 계산이 가능한 Fitting 종류를 알아보겠습니다.  \n",
    " #### (MCMC, MAP, NormApprox, Metropolis, Gibbs) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 5.1 Creating Models \n",
    "  \n",
    " #### 지지난 시간, 동전 던지기에 대한 간단한 실습이 있었는데, MCMC를 돌리기 위한 과정은 \n",
    " \n",
    " ### 데이터 입력 -> 입력값들 모델링 -> MCMC에 입력 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [-----------------100%-----------------] 10000 of 10000 complete in 0.3 sec\n",
      "Mint:\n",
      " \n",
      "\tMean             SD               MC Error        95% HPD interval\n",
      "\t------------------------------------------------------------------\n",
      "\t0.309            0.063            0.002            [ 0.196  0.441]\n",
      "\t\n",
      "\t\n",
      "\tPosterior quantiles:\n",
      "\t\n",
      "\t2.5             25              50              75             97.5\n",
      "\t |---------------|===============|===============|---------------|\n",
      "\t0.197            0.267           0.303          0.35          0.444\n",
      "\t\n",
      "Plotting Mint\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# data from experiment \n",
    "f1=open('z15N50.csv','r')\n",
    "L1=[float(ii) for ii in f1]\n",
    "n=len(L1)\n",
    "\n",
    "\n",
    "# Modelling \n",
    "mint =pm.Beta('Mint',alpha=1,beta=1)\n",
    "coin0=pm.Bernoulli('coin01',p=mint,value=L1,observed=True)\n",
    "\n",
    "M0=pm.Model([mint,coin0])\n",
    "\n",
    "\n",
    "# Fitting \n",
    "M=pm.MCMC(M0) # == pm.MCMC([mint,coin0])\n",
    "M.sample(iter=10000,burn=1000,thin=10)\n",
    "\n",
    "\n",
    "# Print \n",
    "M.summary()\n",
    "pm.Matplot.plot(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 장에서는 입력값을 각 노드로 셋팅할 때의 방법에 대해서 간단하게 설명하고 있습니다. MCMC 명령에 직접 데이터를 연결하는 것도 방법이겠으나, pyMC 에서는 Model() 이라는 명령어로도 사용이 가능합니다.  \n",
    "\n",
    "\n",
    " - M = Model(set([a,b,c]))\n",
    "\n",
    " - M = Model({`a': a, `d': [b,c]}) \n",
    "\n",
    " - M = Model([[a,b],c])\n",
    "\n",
    " - in case that MyModule.py has model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MyModule\n",
    "M = Model(MyModule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Using a ‘model factory’ function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model(x):\n",
    "    a = pymc.Exponential('a', beta=x, value=0.5)\n",
    "\n",
    "    @pymc.deterministic\n",
    "    def b(a=a):\n",
    "        return 100-a\n",
    "\n",
    "    @pymc.stochastic\n",
    "    def c(value=.5, a=a, b=b):\n",
    "        return (value-a)**2/b\n",
    "\n",
    "    return locals()\n",
    "\n",
    "M = pymc.Model(make_model(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  # 5.2 Model Class\n",
    "  \n",
    "   ####  Model() argument  : Model 명령어로 노드 들을 묶을 때\n",
    "    - Input : \n",
    "     Some collection of PyMC nodes defining a probability model. These may be stored in a list, set, tuple,  \n",
    "     dictionary, array, module, or any object with a __dict__ attribute.\n",
    "    - Verbose : \n",
    "     An integer controlling the verbosity of the model’s output.\n",
    " \n",
    "   #### ? Useful Method \n",
    "    - draw_from_prior():\n",
    "     Sets all stochastic variables’ values to new random values, which would be a sample from the joint distribution \n",
    "     if all data and Potential instances’ log-probability functions returned zero. \n",
    "    - seed():\n",
    "     Same as draw_from_prior, but only stochastics whose rseed attribute is not None are changed.\n",
    "        \n",
    "   #### Attributes\n",
    "     variables\n",
    "     nodes\n",
    "     stochastics\n",
    "     potentials\n",
    "     deterministics\n",
    "     observed_stochastics\n",
    "     containers\n",
    "     value\n",
    "     logp\n",
    "    \n",
    "    \n",
    "  # 5.3  Maximum a posteriori estimates¶\n",
    "  \n",
    "   Scipy 의 최적화 코드를 이용하여 maximum a posteriori values 를 계산할 수 있습니다. (SciPy는 설치 되어 있어야합니다.) float 에 대해서면 계산 가능하고  examples/gelman_bioassay.py using MAP (Nelder-Mead optimization) 을 계산 할 수 있습니다. \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<pymc.CommonDeterministics.Lambda 'LD50' at 0x10aee4250>,\n",
       " <pymc.distributions.Binomial 'deaths' at 0x10af64d50>,\n",
       " <pymc.CommonDeterministics.Lambda 'theta' at 0x10af64dd0>,\n",
       " <pymc.distributions.Normal 'alpha' at 0x10aeeba10>,\n",
       " <pymc.distributions.Normal 'beta' at 0x10aeeb9d0>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymc.examples import gelman_bioassay\n",
    "M = pymc.MAP(gelman_bioassay)\n",
    "M.fit()  #fit(method ='fmin', iterlim=1000, tol=.0001): fmin, fmin_l_bfgs_b, fmin_ncg, fmin_cg, or fmin_powell\n",
    "         #Scipy optimization page...\n",
    "\n",
    "         #revert_to_max(): If the values of the constituent (...?) stochastic variables change after fitting, \n",
    "         # this function will reset them to their maximum a posteriori values. \n",
    "\n",
    "           \n",
    "# Attributes        \n",
    "#M.variables\n",
    "M.nodes\n",
    "#M.alpha.value \n",
    "#M.beta.value\n",
    "#M.AIC\n",
    "#M.BIC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # 5.4 Normal approximations\n",
    "  \n",
    "    The NormApprox class extends the MAP class by approximating the posterior covariance of the model using the Fisher information matrix, or the Hessian of the joint log probability at the maximum.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.65231548])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymc\n",
    "from pymc.examples import gelman_bioassay\n",
    "\n",
    "N = pymc.NormApprox(gelman_bioassay)\n",
    "N.fit()\n",
    "\n",
    "\n",
    "N.mu[N.alpha]\n",
    "#N.mu[N.alpha, N.beta]\n",
    "#N.C[N.alpha]\n",
    "#N.C[N.alpha, N.beta]\n",
    "\n",
    "#N.sample(100)\n",
    "#N.trace('alpha')[::10]\n",
    "#N.trace('beta')[::10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # 5.5. Markov chain Monte Carlo: the MCMC class\n",
    "  \n",
    "  ###  sample(iter, burn, thin, tune_interval, tune_throughout, save_interval, ...):  계산 중간 중간에 연산된 값들을 저장. \n",
    "   \n",
    "    iter : ontrols the total number of MCMC iterations. \n",
    "   \n",
    "    the first burn iterations; these samples will be forgotten. After this burn-in period, \n",
    "    \n",
    "    tallying will be done each thin iterations. \n",
    "    \n",
    "    ? tuning will be done each tune_interval iterations. \n",
    "    \n",
    "    ? tune_throughout=False, no more tuning will be done after the burnin period. \n",
    "    \n",
    "    The model state will be saved every save_interval iterations, if given.\n",
    "    \n",
    "\n",
    "  #### isample(iter, burn, thin, tune_interval, tune_throughout, save_interval, ...):  The sampling loop may be paused  at any time, returning control to the user.\n",
    "    \n",
    " \n",
    "  #### use_step_method(method, *args, **kwargs):  Creates an instance of step method class method to handle some stochastic variables. \n",
    "    \n",
    "    \n",
    "  #### goodness():  Calculates goodness-of-fit (GOF) statistics according to [Brooks2000].\n",
    "    \n",
    "\n",
    "  #### save_state(): Saves the current state of the sampler, including all stochastics, to the database. This allows the sampler to be reconstituted at a later time to resume sampling. This is not supported yet for the sqlite backend.\n",
    "  \n",
    "\n",
    "  #### restore_state(): Restores the sampler to the state stored in the database. \n",
    "\n",
    "  #### stats(): Generate summary statistics for all nodes in the model.\n",
    "  \n",
    "  #### remember(trace_index): Set all variables’ values from frame trace_index in the database.  \n",
    "  \n",
    "  \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5.6 Sampler Class\n",
    "   ### MCMC 가 Sampler Class의 서브 클래스이고, sample(iter, length, verbose, ...) 명령으로 joint distribution에 대해 계산. \n",
    "   \n",
    "   - sample(iter, length, verbose, ...):\n",
    "     Samples from the joint distribution. The iter argument controls how many times the sampling loop will be run, and \n",
    "     the length argument controls the initial size of the database that will be used to store the samples.\n",
    "   \n",
    "   ### 그 외, isample(iter, length, verbose, ...), icontinue(), halt(), tally(), save_state(), restore_state(), stats(),  remember(trace_index) 의 옵션이 있습니다. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5.7 Step Method\n",
    "  \n",
    "     Metropolis, AdaptiveMetropolis and Slicer 가 사용 가능하고, tune() 으로 계산 도중의 값들 및 셋팅 조절이 가능 \n",
    "  \n",
    "  \n",
    "   ## 5.7.1  Metropolis step methods\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M.use_step_method(pymc.Metropolis, x, proposal_sd=1., proposal_distribution='Normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - propose(): Sets the values of the variables handled by the Metropolis step method to proposed values.\n",
    "\n",
    "   - reject(): If the Metropolis-Hastings acceptance test fails, this method is called to reset the values of the           variables to their values before propose() was called.\n",
    "\n",
    "   - Note that there is no accept() method\n",
    "   \n",
    "   - proposal_sd: A float or array of floats. This sets the proposal standard deviation if the proposal distribution \n",
    "     is normal.\n",
    "     \n",
    "\n",
    " \n",
    "   ## 5.7.2  The AdaptiveMetropolis class\n",
    "   - Its variables are block-updated using a multivariate jump distribution whose covariance is tuned during sampling\n",
    "   - 따라서, Non Markovian \n",
    "     \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MAP' object has no attribute 'use_step_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1af4e348c880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_step_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpymc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdaptiveMetropolis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                    \u001b[0mscales\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'z'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MAP' object has no attribute 'use_step_method'"
     ]
    }
   ],
   "source": [
    "M.use_step_method(pymc.AdaptiveMetropolis, [x,y,z], \\\n",
    "                   scales={'x':1, 'y':2, 'z':.5}, delay=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### 5.7.3~5.7.5 \n",
    "   #### The DiscreteMetropolis class/  The BinaryMetropolis class / The Slicer class 도 계산 가능합니당. \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 5.8. Gibbs step methods\n",
    "     \n",
    "    `parent’ 와  `children’의 요소로 나뉘어진 입력을 가집니다. 예를 들면, 정상 분포를 따르는 몇개의 변수의 조건이 a gamma-distributed variable 을 따른다고 할 때, gamma variable -> the parent, the normal variables -> the children. \n",
    "    \n",
    "\n",
    "   ### 5.8.1. Granularity of step methods: one-at-a-time vs. block updating\n",
    "    There is currently no way for a stochastic variable to compute individual terms of its log-probability; it is computed all together. This means that updating the elements of a array-valued variable individually would be inefficient, so all existing step methods update array-valued variables together, in a block update.\n",
    "\n",
    "    To update an array-valued variable’s elements individually, simply break it up into an array of scalar-valued variables. Instead of this: An individual step method will be assigned to each element of A in the latter case, and the elements will be updated individually. Note that A can be broken up into larger blocks if desired.\n",
    "\n",
    "\n",
    "\n",
    "   ### 5.8.2. Automatic assignment of step methods\n",
    "\n",
    "    Every step method subclass (including user-defined ones) that does not require any __init__ arguments other than the stochastic variable to be handled adds itself to a list called StepMethodRegistry in the PyMC namespace. If a stochastic variable in an MCMC object has not been explicitly assigned a step method, each class in StepMethodRegistry is allowed to examine the variable.\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
